{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "> In this lab, I am attempting to learn how to effectively clean data. To do that, I have been provided three datasets that are 'messy,' and each requires different cleaning techniques. The goal of the lab is to clean as many of the datasets in as thorough of a way before the deadline. That being said, the datasets are certainly very messy and my experience with Pandas is limited, so the cleaning done on each dataset will be imperfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing and aliasing required packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Opening Excel file and creating a reference list of the column headers: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Are you going actually going trick or treating yourself?</th>\n",
       "      <th>Your gender:</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>Which country do you live in?</th>\n",
       "      <th>Which state, province, county do you live in?</th>\n",
       "      <th>[100 Grand Bar]</th>\n",
       "      <th>[Anonymous brown globs that come in black and orange wrappers]</th>\n",
       "      <th>[Any full-sized candy bar]</th>\n",
       "      <th>[Black Jacks]</th>\n",
       "      <th>...</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Beyoncé]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Bieber]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]</th>\n",
       "      <th>Which day do you prefer, Friday or Sunday?</th>\n",
       "      <th>Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?</th>\n",
       "      <th>When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).</th>\n",
       "      <th>[York Peppermint Patties] Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-24 05:09:23.033</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>2</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-24 05:09:54.798</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>MEH</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-24 05:13:06.734</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-24 05:14:17.192</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-24 05:14:24.625</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  \\\n",
       "0 2016-10-24 05:09:23.033   \n",
       "1 2016-10-24 05:09:54.798   \n",
       "2 2016-10-24 05:13:06.734   \n",
       "3 2016-10-24 05:14:17.192   \n",
       "4 2016-10-24 05:14:24.625   \n",
       "\n",
       "  Are you going actually going trick or treating yourself? Your gender:  \\\n",
       "0                                                 No               Male   \n",
       "1                                                 No               Male   \n",
       "2                                                 No             Female   \n",
       "3                                                 No               Male   \n",
       "4                                                Yes               Male   \n",
       "\n",
       "  How old are you? Which country do you live in?  \\\n",
       "0               22                        Canada   \n",
       "1               45                           usa   \n",
       "2               48                            US   \n",
       "3               57                           usa   \n",
       "4               42                           USA   \n",
       "\n",
       "  Which state, province, county do you live in?  [100 Grand Bar]  \\\n",
       "0                                       Ontario              JOY   \n",
       "1                                            il              MEH   \n",
       "2                                      Colorado              JOY   \n",
       "3                                            il              JOY   \n",
       "4                                  South Dakota              MEH   \n",
       "\n",
       "   [Anonymous brown globs that come in black and orange wrappers]  \\\n",
       "0                                            DESPAIR                \n",
       "1                                                MEH                \n",
       "2                                            DESPAIR                \n",
       "3                                                MEH                \n",
       "4                                            DESPAIR                \n",
       "\n",
       "   [Any full-sized candy bar]  [Black Jacks]  \\\n",
       "0                         JOY            MEH   \n",
       "1                         JOY            JOY   \n",
       "2                         JOY            MEH   \n",
       "3                         JOY            MEH   \n",
       "4                         JOY        DESPAIR   \n",
       "\n",
       "                 ...                 \\\n",
       "0                ...                  \n",
       "1                ...                  \n",
       "2                ...                  \n",
       "3                ...                  \n",
       "4                ...                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]  \\\n",
       "0                                        3 or higher                                                 \n",
       "1                                        3 or higher                                                 \n",
       "2                                        3 or higher                                                 \n",
       "3                                        3 or higher                                                 \n",
       "4                                        3 or higher                                                 \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]  \\\n",
       "0                                                  2                                                \n",
       "1                                        3 or higher                                                \n",
       "2                                        3 or higher                                                \n",
       "3                                        3 or higher                                                \n",
       "4                                        3 or higher                                                \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Beyoncé]  \\\n",
       "0                                        3 or higher                                              \n",
       "1                                        3 or higher                                              \n",
       "2                                        3 or higher                                              \n",
       "3                                        3 or higher                                              \n",
       "4                                        3 or higher                                              \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Bieber]  \\\n",
       "0                                        3 or higher                                             \n",
       "1                                        3 or higher                                             \n",
       "2                                        3 or higher                                             \n",
       "3                                        3 or higher                                             \n",
       "4                                        3 or higher                                             \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]  \\\n",
       "0                                        3 or higher                                                  \n",
       "1                                        3 or higher                                                  \n",
       "2                                        3 or higher                                                  \n",
       "3                                        3 or higher                                                  \n",
       "4                                        3 or higher                                                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]  \\\n",
       "0                                        3 or higher                                                                  \n",
       "1                                        3 or higher                                                                  \n",
       "2                                        3 or higher                                                                  \n",
       "3                                        3 or higher                                                                  \n",
       "4                                        3 or higher                                                                  \n",
       "\n",
       "  Which day do you prefer, Friday or Sunday?  \\\n",
       "0                                     Friday   \n",
       "1                                     Friday   \n",
       "2                                     Sunday   \n",
       "3                                     Sunday   \n",
       "4                                     Friday   \n",
       "\n",
       "  Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?  \\\n",
       "0                                     South to North                                                                                          \n",
       "1                                       East to West                                                                                          \n",
       "2                                       East to West                                                                                          \n",
       "3                                     South to North                                                                                          \n",
       "4                                       East to West                                                                                          \n",
       "\n",
       "  When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).  \\\n",
       "0                 Science: Latest News and Headlines                                                                        \n",
       "1                 Science: Latest News and Headlines                                                                        \n",
       "2                 Science: Latest News and Headlines                                                                        \n",
       "3                 Science: Latest News and Headlines                                                                        \n",
       "4                                               ESPN                                                                        \n",
       "\n",
       "   [York Peppermint Patties] Ignore  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('./BOING-BOING-CANDY-HIERARCHY-2016-SURVEY-Responses.xlsx')\n",
    "c1 = list(df1.columns.values)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Changing every response in columns 2 and 3 (indexes 1 and 2) to one letter for ease of manipulation: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       N\n",
       "1       N\n",
       "2       N\n",
       "3       N\n",
       "4       Y\n",
       "5       N\n",
       "6       Y\n",
       "7       N\n",
       "8       Y\n",
       "9       N\n",
       "10      N\n",
       "11      N\n",
       "12      N\n",
       "13      Y\n",
       "14      N\n",
       "15      N\n",
       "16      N\n",
       "17      N\n",
       "18      Y\n",
       "19      N\n",
       "20      N\n",
       "21      N\n",
       "22      N\n",
       "23      N\n",
       "24      N\n",
       "25      N\n",
       "26      N\n",
       "27      N\n",
       "28      N\n",
       "29      N\n",
       "       ..\n",
       "1229    N\n",
       "1230    N\n",
       "1231    N\n",
       "1232    N\n",
       "1233    N\n",
       "1234    N\n",
       "1235    N\n",
       "1236    N\n",
       "1237    N\n",
       "1238    N\n",
       "1239    N\n",
       "1240    N\n",
       "1241    N\n",
       "1242    N\n",
       "1243    Y\n",
       "1244    N\n",
       "1245    N\n",
       "1246    N\n",
       "1247    N\n",
       "1248    N\n",
       "1249    Y\n",
       "1250    N\n",
       "1251    N\n",
       "1252    Y\n",
       "1253    N\n",
       "1254    N\n",
       "1255    N\n",
       "1256    N\n",
       "1257    N\n",
       "1258    Y\n",
       "Name: Are you going actually going trick or treating yourself?, Length: 1259, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1[c1[1]] == \"Yes\", c1[1]] = 'Y'\n",
    "df1.loc[df1[c1[1]] == \"No\", c1[1]] = 'N'\n",
    "\n",
    "df1[c1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       M\n",
       "1       M\n",
       "2       F\n",
       "3       M\n",
       "4       M\n",
       "5       M\n",
       "6       M\n",
       "7       M\n",
       "8       M\n",
       "9       F\n",
       "10      O\n",
       "11      F\n",
       "12      M\n",
       "13      M\n",
       "14      M\n",
       "15      F\n",
       "16      F\n",
       "17      M\n",
       "18      M\n",
       "19      M\n",
       "20      M\n",
       "21      M\n",
       "22      M\n",
       "23      F\n",
       "24      M\n",
       "25      M\n",
       "26      F\n",
       "27       \n",
       "28      M\n",
       "29       \n",
       "       ..\n",
       "1229    M\n",
       "1230    M\n",
       "1231    O\n",
       "1232    F\n",
       "1233    F\n",
       "1234    F\n",
       "1235    F\n",
       "1236    M\n",
       "1237    F\n",
       "1238    F\n",
       "1239    F\n",
       "1240    M\n",
       "1241    F\n",
       "1242    M\n",
       "1243    M\n",
       "1244    F\n",
       "1245    F\n",
       "1246    M\n",
       "1247    F\n",
       "1248    M\n",
       "1249    F\n",
       "1250    M\n",
       "1251    F\n",
       "1252    F\n",
       "1253    M\n",
       "1254    F\n",
       "1255    M\n",
       "1256    M\n",
       "1257    M\n",
       "1258    F\n",
       "Name: Your gender:, Length: 1259, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1[c1[2]] == \"Male\", c1[2]] = 'M'\n",
    "df1.loc[df1[c1[2]] == \"Female\", c1[2]] = 'F'\n",
    "df1.loc[df1[c1[2]] == \"Other\", c1[2]] = 'O'\n",
    "df1.loc[df1[c1[2]] == \"I'd rather not say\", c1[2]] = ''\n",
    "\n",
    "df1[c1[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting all ages to integers, and logging all non-integer responses:**\n",
    "> Some people responded with sentences instead of numbers, which will be thrown out. Ideally, they would be parsed, but that requires more coding knowledge than I currently have, and probably an advanced neural netowrk. Instead, I logged all non-number responses, which are a negligible part of the total column (most answers are in integer form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on: Old enough to know better \n",
      "Failed on: old enough\n",
      "Failed on: As old as my tongue a few years older than my teeth\n",
      "Failed on: 50s\n",
      "Failed on: old\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: 0x2A\n",
      "Failed on: Fifty.  Nine.  Ish.\n",
      "Failed on: nan\n",
      "Failed on: Ancient\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: I remember the Nixon administration\n",
      "Failed on: over retirement age\n",
      "Failed on: old\n",
      "Failed on: nan\n",
      "Failed on: Old enough\n",
      "Failed on: 50+\n",
      "Failed on: 55+\n",
      "Failed on: over 40\n",
      "Failed on: nan\n",
      "Failed on: Hahahahahaha\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: old enough\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: Old\n",
      "Failed on: Older than i act\n",
      "Failed on: nan\n",
      "Failed on: really old\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: blah\n",
      "Failed on: nan\n",
      "Failed on: older than I want to be\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: Not as old as you...\n",
      "Failed on: Old\n",
      "Failed on: Never ask a woman that question.\n",
      "Failed on: Not as old as you...\n",
      "Failed on: old \n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: Old enough\n",
      "Failed on: old enough\n",
      "Failed on: Same as yo mama\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: 50+\n",
      "Failed on: nan\n",
      "Failed on: Too old to trick or treat without it being creepy\n",
      "Failed on: nan\n",
      "Failed on: nan\n",
      "Failed on: ancient\n",
      "Failed on: Old enough to not Trick or Treat.\n",
      "Failed on: nan\n",
      "Failed on: 49 11/12ths\n",
      "Failed on: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       22.0\n",
       "1       45.0\n",
       "2       48.0\n",
       "3       57.0\n",
       "4       42.0\n",
       "5       41.0\n",
       "6       47.0\n",
       "7       28.0\n",
       "8       44.0\n",
       "9       41.0\n",
       "10      34.0\n",
       "11      46.0\n",
       "12      41.0\n",
       "13      45.0\n",
       "14      40.0\n",
       "15      31.0\n",
       "16      33.0\n",
       "17      35.0\n",
       "18      49.0\n",
       "19      44.0\n",
       "20      45.0\n",
       "21      34.0\n",
       "22      48.0\n",
       "23      16.0\n",
       "24      60.0\n",
       "25      30.0\n",
       "26      51.0\n",
       "27      31.0\n",
       "28      51.0\n",
       "29      33.0\n",
       "        ... \n",
       "1229    31.0\n",
       "1230    51.0\n",
       "1231    33.0\n",
       "1232    25.0\n",
       "1233    29.0\n",
       "1234    26.0\n",
       "1235    44.0\n",
       "1236    24.0\n",
       "1237    31.0\n",
       "1238    71.0\n",
       "1239    32.0\n",
       "1240    27.0\n",
       "1241    26.0\n",
       "1242    46.0\n",
       "1243    45.0\n",
       "1244    45.0\n",
       "1245     NaN\n",
       "1246    31.0\n",
       "1247    31.0\n",
       "1248    27.0\n",
       "1249    47.0\n",
       "1250    35.0\n",
       "1251    34.0\n",
       "1252    56.0\n",
       "1253    54.0\n",
       "1254    52.0\n",
       "1255    33.0\n",
       "1256     NaN\n",
       "1257    48.0\n",
       "1258    44.0\n",
       "Name: How old are you?, Length: 1259, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_num(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        print('Failed on: %s' %x)\n",
    "        x = np.nan\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Apply function above to every item in column 4 as a lambda function\n",
    "df1[c1[3]] = df1[c1[3]].apply(lambda x: to_num(x))\n",
    "\n",
    "df1[c1[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting all responses to integers, for ease of manipulation: **\n",
    "> Here, I went through every candy column and converted the responses, which could be either 'JOY', 'MEH', or 'DESPAIR' (or no response) to integer values. This would allow me in the future to do more advanced manipulations, such as finding the mean feeling towards a certain candy. In this case, 'JOY' is a 10, 'MEH' is a 5, and 'DESPAIR' is a 0. I applied this to all 100 columns where the answers are limited to those three (or no response). If there is no response, I logged it as a NaN, instead of making it 0 (then every no response would be a 'DESPAIR'). This step would ultimately make analysis in the future much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10.0\n",
       "1        5.0\n",
       "2       10.0\n",
       "3       10.0\n",
       "4        5.0\n",
       "5       10.0\n",
       "6        0.0\n",
       "7        5.0\n",
       "8        5.0\n",
       "9        0.0\n",
       "10      10.0\n",
       "11       5.0\n",
       "12       5.0\n",
       "13       5.0\n",
       "14       5.0\n",
       "15       5.0\n",
       "16      10.0\n",
       "17       NaN\n",
       "18       5.0\n",
       "19       5.0\n",
       "20      10.0\n",
       "21       5.0\n",
       "22       5.0\n",
       "23       5.0\n",
       "24       NaN\n",
       "25       5.0\n",
       "26       5.0\n",
       "27       5.0\n",
       "28       5.0\n",
       "29      10.0\n",
       "        ... \n",
       "1229    10.0\n",
       "1230    10.0\n",
       "1231    10.0\n",
       "1232     0.0\n",
       "1233    10.0\n",
       "1234     5.0\n",
       "1235    10.0\n",
       "1236     5.0\n",
       "1237     5.0\n",
       "1238    10.0\n",
       "1239    10.0\n",
       "1240     0.0\n",
       "1241     5.0\n",
       "1242    10.0\n",
       "1243    10.0\n",
       "1244    10.0\n",
       "1245     5.0\n",
       "1246     NaN\n",
       "1247    10.0\n",
       "1248     5.0\n",
       "1249     5.0\n",
       "1250    10.0\n",
       "1251    10.0\n",
       "1252    10.0\n",
       "1253     5.0\n",
       "1254    10.0\n",
       "1255    10.0\n",
       "1256    10.0\n",
       "1257     NaN\n",
       "1258    10.0\n",
       "Name:  [100 Grand Bar], Length: 1259, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_value(x):\n",
    "    try:\n",
    "        if 'J' in x:\n",
    "            x = 10\n",
    "        elif 'M' in x:\n",
    "            x = 5\n",
    "        elif 'D' in x:\n",
    "            x = 0\n",
    "    except:\n",
    "        x = np.nan\n",
    "        \n",
    "    return x\n",
    "\n",
    "# run on each 'JOY', 'MEH', 'DESPAIR' column\n",
    "for i in range(6, 106):\n",
    "    df1[c1[i]] = df1[c1[i]].apply(lambda x: to_value(x))\n",
    "    \n",
    "df1[c1[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 1 further steps:**\n",
    "> If I had more time with the candy data, I would rename every single column header (as they are pretty useless right now), and I would actually analyze my data. I would also look at the columns that I didn't get to in order to find the cleaning method that's right for them. Finally, I would try to convert every country to a code, so that I could do analysis based on region. I do not have the coding expertise or time to do most of these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Opening Excel file and creating a reference list of the column headers:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('./attendance.xls', skiprows=2)\n",
    "c2 = list(df2.columns.values)\n",
    "\n",
    "df2.drop(df2.index[0])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dataset 2 further steps:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No cleaning steps have been taken to clean dataset 2. That is largely due to both the amount of time it took to learn pandas cleaning in dataset 1, and also due to  the lack of time I have had to work on datasets two and three. Unfortunately, after completing my cleaning on dataset 1, I had to both go on a college visit trip and write ~5000 words of supplementals. Regardless, there are a many things I would do to dataset 2 if given the time.\n",
    "\n",
    "> If I had more time to work on dataset 2, I would primarily spend time reorganizing the column sections into distinc columns of their own. Since each is currently split up into subsections, it would be easier to find and ultimately analyze specified data. Then I would convert each item in the dataframe (not including the row/column headers) from a string to a float. This might include removing all of the parentheses. I would then convert all of the extraneous symbols in the items to NaN's, so that they can be either ignored or used easier. Finally, I would begin my analysis, because the data is at that point cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Opening Excel file and creating a reference list of the column headers:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('./sales.csv', encoding='ISO-8859-1')\n",
    "c3 = list(df3.columns.values)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dataset 3 further steps:***\n",
    "> Similarly to dataset 2, I did not have time to work on dataset 3. That being said, tehre are several things I would do to dataset 3 if given the time.\n",
    "\n",
    "> If I had more time to work on dataset 3, I would begin by changing every 'NULL' to NaN, so that they can be searched for more easily and either used/ignored. Then, I would change every item in the major_cat_name and minor_cat_name columns to only one letter, similarly to how I did for dataset 1. After this, I would change every item in the ticket_text to have slashes instead of spaces, but only if there are more than two consecutive spaces (so that it doesn't change the spaces in between words). Finally, I would change every 'NA' to a 0, so that they can both be distinguished from the 'NULL's (which would be at that point NaN's) and so that they can be easier to analyze. I would then begin my analysis, because the data is at that point cleaned.\n",
    "\n",
    "> It is very unfortunate that I did not have the time to clean this dataset, as it particularly interested me. I have the skillset to do all of the cleaning that I mentioned above, but it could take anywhere from 2-4 hours to do, and I just can't spare any more time outside of class to work on this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Ms. Sconyers: ***\n",
    "> I would like to thank Ms. Sconyers for both providing the datasets for this lab as well as helping the class figure out how to drop different rows/columns. She was very helpful in helping me learn how to use pandas more effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
